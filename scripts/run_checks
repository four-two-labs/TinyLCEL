#!/bin/bash
set -euo pipefail

# Configuration
COVERAGE_THRESHOLD=85

# Stage control flags (all enabled by default)
RUN_GIT_STATUS=true
RUN_FORMATTING=true
RUN_LINT=true
RUN_TYPE_CHECK=true
RUN_UNIT_TESTS=true
RUN_COVERAGE=true
RUN_COMPLEXITY=true
RUN_METRICS=true

# Track if any specific flags were provided
FLAGS_PROVIDED=false

# Parse command line arguments
parse_args() {
    # First pass: check if any stage flags were provided
    for arg in "$@"; do
        case $arg in
            --git|--format|--lint|--type|--unit-tests|--tests|--coverage|--complexity|--metrics)
                FLAGS_PROVIDED=true
                break
                ;;
        esac
    done
    
    # If flags were provided, disable all by default, then enable selected ones
    # Note: formatting always runs regardless of flags
    if [ "$FLAGS_PROVIDED" = true ]; then
        RUN_GIT_STATUS=false
        RUN_LINT=false
        RUN_TYPE_CHECK=false
        RUN_UNIT_TESTS=false
        RUN_COVERAGE=false
        RUN_COMPLEXITY=false
        RUN_METRICS=false
        # RUN_FORMATTING stays true - formatting always runs
    fi
    
    # Second pass: enable specified stages
    while [[ $# -gt 0 ]]; do
        case $1 in
            --git)
                RUN_GIT_STATUS=true
                shift
                ;;
            --format)
                RUN_FORMATTING=true
                shift
                ;;
            --lint)
                RUN_LINT=true
                shift
                ;;
            --type)
                RUN_TYPE_CHECK=true
                shift
                ;;
            --unit-tests|--tests)
                RUN_UNIT_TESTS=true
                shift
                ;;
            --coverage)
                RUN_COVERAGE=true
                shift
                ;;
            --complexity)
                RUN_COMPLEXITY=true
                shift
                ;;
            --metrics)
                RUN_METRICS=true
                shift
                ;;
            --help|-h)
                show_help
                exit 0
                ;;
            *)
                echo "Unknown option: $1"
                echo "Use --help for usage information"
                exit 1
                ;;
        esac
    done
}

show_help() {
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Run code quality checks for the project."
    echo "By default, all checks are enabled when no stage flags are specified."
    echo "When stage flags are provided, only those stages will run."
    echo "Note: Code formatting always runs regardless of flags."
    echo ""
    echo "Stage Options:"
    echo "  --git                    Run git status check"
    echo "  --format                 Run code formatting (always runs anyway)"
    echo "  --lint                   Run lint checks"
    echo "  --type                   Run type checks"
    echo "  --unit-tests, --tests    Run unit tests"
    echo "  --coverage               Run test coverage check"
    echo "  --complexity             Run McCabe complexity check"
    echo "  --metrics                Run code quality metrics"
    echo ""
    echo "Other Options:"
    echo "  --help, -h               Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0                                  Run all checks (default)"
    echo "  $0 --lint --type                   Run formatting + lint + type checks"
    echo "  $0 --tests --coverage               Run formatting + tests + coverage"
    echo "  $0 --unit-tests --metrics           Run formatting + unit tests + metrics"
}

# Global variables for tracking results
FAILED_CHECKS=""
TOTAL_AUTO_FIXES=0
TEST_OUTPUT=""
SLOC="N/A"
COVERAGE_PERCENT="N/A"

# Check that specified tools are available in the virtual environment
check_venv_tools() {
    local tools=("$@")
    local venv_missing=()
    
    info "🔍 Checking virtual environment..."
    
    for tool in "${tools[@]}"; do
        [ ! -f "$VENV_BIN_PATH/$tool" ] && venv_missing+=("$tool")
    done
    
    if [ ${#venv_missing[@]} -gt 0 ]; then
        error "❌ Missing tools in virtual environment:"
        for tool in "${venv_missing[@]}"; do
            error "  - $tool"
        done
        echo
        warning "Please install project dependencies: ./configure_env.sh"
        exit 1
    fi
    
    info "${GREEN}✅ Virtual environment ready${NC}"
    echo
}

find_venv_bin_path() {
    local venv_activate
    venv_activate=$(locate_venv_bin_path "$PROJECT_ROOT")
    
    if [ -z "$venv_activate" ]; then
        error "No virtual environment found"
        exit 1
    fi
    
    VENV_BIN_PATH=$(dirname "$venv_activate")
    echo $VENV_BIN_PATH
}

# Build common command with config
build_cmd() {
    local tool="$1"
    local args="$2"
    local config_param="${3:---config}"  # Default to --config if not specified
    
    if [ "$config_param" = "none" ]; then
        # No config parameter needed
        echo "$VENV_BIN_PATH/$tool $args"
    else
        echo "$VENV_BIN_PATH/$tool $config_param $PROJECT_ROOT/pyproject.toml $args"
    fi
}

# Simplified function to run any check
run_check() {
    local check_name="$1"
    local check_command="$2"
    local success_message="${3:-OK}"
    local clear_on_success="${4:-false}"
    
    echo
    echo -e "===${ORANGE}${check_name}${NC}==="
    
    set +e
    execute_command "$check_command" "$clear_on_success"
    local exit_code=$COMMAND_EXIT_CODE
    local output="$COMMAND_OUTPUT"
    set -e
    
    # Store test output for summary
    case "$check_name" in
        "Unit tests") TEST_OUTPUT="$output" ;;
    esac
    
    # Handle success/failure
    if [ $exit_code -eq 0 ]; then
        echo -e "${GREEN}${success_message}${NC}"
    else
        if [ "$clear_on_success" = "true" ]; then
            echo
            echo -e "${RED}${check_name} failed - see output above for details${NC}"
        else
            echo -e "${RED}${check_name} failed${NC}"
        fi
        FAILED_CHECKS="$FAILED_CHECKS $check_name"
    fi
    echo
}

run_git_status_check() {
    echo
    echo -e "===${ORANGE}Git status${NC}==="
    
    set +e
    local modified_tracked untracked_py has_issues exit_code
    
    # Check for modified tracked files not staged for commit
    modified_tracked=$(git ls-files --modified 2>/dev/null || true)
    
    # Check for untracked Python files
    untracked_py=$(git ls-files --others --exclude-standard 2>/dev/null | grep '\.py$' || true)
    
    has_issues=false
    
    if [ -n "$modified_tracked" ]; then
        echo -e "Modified tracked files not staged for commit:"
        echo "$modified_tracked" | while read -r file; do
            if [ -n "$file" ]; then
                echo -e "  - ${LIGHT_RED}$file${NC}"
            fi
        done
        echo
        has_issues=true
    fi
    
    if [ -n "$untracked_py" ]; then
        echo -e "Untracked Python files:"
        echo "$untracked_py" | while read -r file; do
            if [ -n "$file" ]; then
                echo -e "  - ${ORANGE}$file${NC}"
            fi
        done
        echo
        has_issues=true
    fi
    
    if [ "$has_issues" = true ]; then
        echo -e "${RED}Git status check failed${NC}"
        FAILED_CHECKS="$FAILED_CHECKS Git status"
        exit_code=1
    else
        echo -e "${GREEN}No unstaged changes or untracked Python files${NC}"
        exit_code=0
    fi
    
    set -e
    echo
}

run_coverage_check() {
    echo
    echo -e "===${ORANGE}Test coverage${NC}==="
    
    set +e
    execute_command "$(build_cmd "pytest" "--color=yes --cov=src --cov-report=term-missing --disable-warnings -q $PROJECT_ROOT/tests" "none")" "true"
    local exit_code=$COMMAND_EXIT_CODE
    local coverage_output="$COMMAND_OUTPUT"
    set -e
    
    # Extract coverage percentage
    local coverage_percent
    coverage_percent=$(echo "$coverage_output" | grep "TOTAL" | awk '{print $NF}' | sed 's/%//' 2>/dev/null || echo "0")
    COVERAGE_PERCENT="${coverage_percent}%"
    
    # Check if successful and meets threshold
    if [ $exit_code -eq 0 ] && [ "$coverage_percent" -ge "$COVERAGE_THRESHOLD" ]; then
        echo -e "${GREEN}Coverage: ${coverage_percent}% (meets ${COVERAGE_THRESHOLD}% minimum)${NC}"
    else
        echo
        if [ $exit_code -ne 0 ]; then
            echo -e "${RED}Test coverage failed - see output above for details${NC}"
        else
            echo -e "${RED}Coverage: ${coverage_percent}% (below ${COVERAGE_THRESHOLD}% minimum)${NC}"
        fi
        FAILED_CHECKS="$FAILED_CHECKS Test coverage"
    fi
    echo
}

apply_formatting() {
    echo
    echo -e "===${ORANGE}Applying code formatting${NC}==="
    
    # Check lint violations before formatting
    local pre_lint_output post_lint_output
    pre_lint_output=$(eval "$(build_cmd "ruff" "check $PROJECT_ROOT/src")" 2>/dev/null || true)
    local pre_lint_count=0
    if [[ "$pre_lint_output" != *"All checks passed!"* ]]; then
        pre_lint_count=$(echo "$pre_lint_output" | wc -l | xargs)
    fi

    # Run isort and count fixes
    local isort_output
    isort_output=$(eval "$(build_cmd "isort" "$PROJECT_ROOT/src $PROJECT_ROOT/tests" "--settings-path")" 2>&1)
    local isort_fixes=$(echo "$isort_output" | grep -c "Fixing " || true)

    # Run ruff format and count fixes
    local ruff_format_output
    ruff_format_output=$(eval "$(build_cmd "ruff" "format $PROJECT_ROOT/src $PROJECT_ROOT/tests")" 2>&1)
    local format_fixes=0
    if [[ "$ruff_format_output" == *"files reformatted"* ]]; then
        format_fixes=$(echo "$ruff_format_output" | grep -o '[0-9]\+' | head -1)
    fi

    # Auto-fix lint issues
    eval "$(build_cmd "ruff" "check --fix --unsafe-fixes $PROJECT_ROOT/src $PROJECT_ROOT/tests")" >/dev/null 2>&1 || true
    
    # Check lint violations after formatting
    post_lint_output=$(eval "$(build_cmd "ruff" "check $PROJECT_ROOT/src")" 2>/dev/null || true)
    local post_lint_count=0
    if [[ "$post_lint_output" != *"All checks passed!"* ]]; then
        post_lint_count=$(echo "$post_lint_output" | wc -l | xargs)
    fi
    
    local lint_fixes_by_format=$((pre_lint_count - post_lint_count))
    if [ "$lint_fixes_by_format" -lt 0 ]; then
        lint_fixes_by_format=0
    fi

    TOTAL_AUTO_FIXES=$((isort_fixes + format_fixes + lint_fixes_by_format))
    
    # Display results
    if [ "$isort_fixes" -gt 0 ]; then
        echo "  📄 Import sorting: Fixed $isort_fixes files"
    fi
    if [ "$format_fixes" -gt 0 ]; then
        echo "  🎨 Code formatting: Fixed $format_fixes files"
    fi
    if [ "$lint_fixes_by_format" -gt 0 ]; then
        echo "  🔧 Lint issues auto-fixed: $lint_fixes_by_format"
    fi
    if [ "$TOTAL_AUTO_FIXES" -eq 0 ]; then
        echo "  ✅ No formatting issues found"
    fi

    echo -e "${GREEN}OK${NC}"
    echo
}

show_code_metrics() {
    echo -e "\n${CYAN}Code metrics:${NC}"
    
    # Simple SLOC count
    SLOC=$(eval "$(build_cmd "radon" "raw --summary $PROJECT_ROOT/src" "none")" 2>/dev/null | grep -A 10 "\*\* Total \*\*" | grep "SLOC:" | awk '{print $2}' || echo "N/A")
    echo "  📊 Source lines: $SLOC"
    
    # Simple complexity average
    local complexity
    complexity=$(eval "$(build_cmd "radon" "cc --total-average $PROJECT_ROOT/src" "none")" 2>/dev/null | grep "Average complexity:" | awk '{print $3}' || echo "N/A")
    echo "  🔄 Average complexity: $complexity"
    
    # Simple maintainability average
    local maintainability
    maintainability=$(eval "$(build_cmd "radon" "mi --show $PROJECT_ROOT/src" "none")" 2>/dev/null | grep -o '([0-9]\+\.[0-9]\+)' | tr -d '()' | awk '{sum+=$1; count++} END {if(count>0) printf "%.1f", sum/count; else print "N/A"}' || echo "N/A")
    echo "  🛠️  Average maintainability: $maintainability"
    
    echo "  ✅ Code metrics complete"
}

show_summary() {
    echo -e "===${CYAN}Summary${NC}==="
    
    local total_files unit_tests_passed
    total_files=$(find "$PROJECT_ROOT/src" -name "*.py" | wc -l | xargs)
    
    # Handle test results based on what was run
    if [ "$RUN_UNIT_TESTS" = true ]; then
        unit_tests_passed=$(echo "$TEST_OUTPUT" | grep -o '[0-9]\+ passed' | tail -1 | awk '{print $1}' 2>/dev/null || echo "0")
    else
        unit_tests_passed="Skipped"
    fi
    
    echo "  📁 Python files: $total_files"
    if [ "$RUN_METRICS" = true ]; then
        echo "  💻 Source lines: $SLOC"
    else
        echo "  💻 Source lines: Skipped"
    fi
    
    if [ "$RUN_UNIT_TESTS" = true ]; then
        echo "  ✅ Unit tests: $unit_tests_passed passed"
    else
        echo "  ✅ Unit tests: Skipped"
    fi
    
    if [ "$RUN_COVERAGE" = true ]; then
        echo "  📊 Test coverage: $COVERAGE_PERCENT"
    else
        echo "  📊 Test coverage: Skipped"
    fi
    
    echo "  🔧 Auto-fixes applied: $TOTAL_AUTO_FIXES"
    
    if [ -n "$FAILED_CHECKS" ]; then
        echo "  ❌ Failed checks:$FAILED_CHECKS"
        echo
        echo -e "${RED}Some checks failed 🚨${NC}"
        exit 1
    else
        echo
        echo -e "${GREEN}All checks passed! 🚀${NC}"
        exit 0
    fi
}

# Main execution
main() {
    # Parse command line arguments
    parse_args "$@"
    
    # Check prerequisites
    check_dependencies \
        '{"curl": {"apt": "curl", "brew": "curl"}, "git": {"apt": "git", "brew": "git"}, "find": {"apt": "findutils", "brew": "findutils"}}'
    
    # Setup and validate virtual environment
    export VENV_BIN_PATH=$(find_venv_bin_path)
    
    # Check virtual environment has required tools
    check_venv_tools python pytest ruff mypy
    
    # Brief pause to show bootstrap results, then clear for clean output
    sleep 1
    clear
    
    # Run all checks
    if [ "$RUN_FORMATTING" = true ]; then
        apply_formatting
    fi
    
    if [ "$RUN_LINT" = true ]; then
        run_check "Lint checks" \
            "$(build_cmd "ruff" "check $PROJECT_ROOT/src $PROJECT_ROOT/tests")"
    fi
    
    if [ "$RUN_TYPE_CHECK" = true ]; then
        run_check "Type checks" \
            "$(build_cmd "mypy" "--color-output $PROJECT_ROOT/src $PROJECT_ROOT/tests")" \
            "OK" \
            "true"
    fi
    
    if [ "$RUN_UNIT_TESTS" = true ]; then
        run_check "Unit tests" \
            "$(build_cmd "pytest" "--color=yes --disable-warnings -q $PROJECT_ROOT/tests" "none")" \
            "OK" \
            "true"
    fi
    
    if [ "$RUN_COVERAGE" = true ]; then
        run_coverage_check
    fi
    
    if [ "$RUN_COMPLEXITY" = true ]; then
        run_check "McCabe complexity" \
            "$(build_cmd "ruff" "check --select C901 $PROJECT_ROOT/src")"
    fi
    
    # Show code quality metrics
    echo
    echo -e "===${ORANGE}Code quality statistics${NC}==="
    
    # Show ruff statistics or clean message
    local stats_output
    stats_output=$(eval "$(build_cmd "ruff" "check --statistics $PROJECT_ROOT/src")" 2>&1 || true)
    if [ -n "$stats_output" ] && [[ "$stats_output" != *"All checks passed!"* ]]; then
        echo "$stats_output"
    else
        echo "🎉 No violations found - clean code!"
    fi
    
    if [ "$RUN_METRICS" = true ]; then
        show_code_metrics
    fi
    
    # Check git status before summary
    if [ "$RUN_GIT_STATUS" = true ]; then
        run_git_status_check
    fi
    
    echo
    show_summary
}

# Run the script
SCRIPT_PATH=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
export PROJECT_ROOT=$(cd "$SCRIPT_PATH/.." && pwd)
source $PROJECT_ROOT/scripts/shared
$PROJECT_ROOT/configure_env.sh 2>&1 > /dev/null
main "$@"